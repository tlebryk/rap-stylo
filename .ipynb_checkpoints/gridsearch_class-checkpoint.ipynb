{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import functools\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.feature_extraction.text import CountVectorizer as CV\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.linear_model import SGDClassifier, LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 109\n",
    "# Currently removing warnings to make the final notebook more attractive \n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json is formatted as list of albums\n",
    "# albums are list of songs with lyrics and other metadata\n",
    "def json_extract(path):\n",
    "    data_list=[]\n",
    "    for file in os.listdir(path): \n",
    "        if file[-5:] == '.json':\n",
    "            with open(path+file, 'r') as f: \n",
    "                data = json.load(f)\n",
    "                data_list.append(data)\n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/drake/'\n",
    "drake = json_extract(path)\n",
    "path = 'data/quentin_miller/'\n",
    "quentin = json_extract(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove obvious identifiers and stem words\n",
    "stops = {'drizzy', 'drake', 'quentin', 'miller', 'ovo', 'champagne', 'papi','toronto', 'atlanta', '6'}\n",
    "analyze = CV().build_analyzer()\n",
    "ps = PorterStemmer()\n",
    "\n",
    "def stop_removal(lyrics : str): \n",
    "    toks = analyze(lyrics)\n",
    "    return ' '.join([ps.stem(word) for word in toks if not ps.stem(word) in stops])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(random_seed)\n",
    "X_train = []\n",
    "train_titles = []\n",
    "d_train_cnt = 0\n",
    "X_val = []\n",
    "val_titles = []\n",
    "d_val_cnt = 0\n",
    "X_test = []\n",
    "test_titles = []\n",
    "d_test_cnt = 0\n",
    "iyrtitl_lyrics = []\n",
    "iyrtitl_titles = []\n",
    "\n",
    "for album in drake: \n",
    "    for song in album: \n",
    "        sample_val = np.random.random(1)\n",
    "        # keep track of \"If you're...\" to put in test set (iytitl is subject to ambiguous authorship)\n",
    "        if song[\"album\"] == \"If You’re Reading This It’s Too Late \":\n",
    "            iyrtitl_titles.append(song['title'])\n",
    "            iyrtitl_lyrics.append(stop_removal(song['lyrics']))\n",
    "        # oversample from Drake to balance training sample. \n",
    "        elif sample_val < .15:\n",
    "            test_titles.append(song['title'])\n",
    "            X_test.append(stop_removal(song['lyrics']))   \n",
    "            d_test_cnt+=1\n",
    "        elif sample_val >= .15 and sample_val <= .3:\n",
    "            val_titles.append(song['title'])\n",
    "            X_val.append(stop_removal(song['lyrics']))   \n",
    "            d_val_cnt+=1\n",
    "        else: \n",
    "            train_titles.append(song['title'])\n",
    "            X_train.append(stop_removal(song['lyrics']))\n",
    "            d_train_cnt+=1\n",
    "\n",
    "for album in quentin: \n",
    "    for song in album:\n",
    "        sample_val = np.random.random(1)\n",
    "        if sample_val < .1:\n",
    "            test_titles.append(song['title'])\n",
    "            X_test.append(stop_removal(song['lyrics'])) \n",
    "        elif sample_val >= 0.1 and sample_val < 0.2:\n",
    "            val_titles.append(song['title'])\n",
    "            X_val.append(stop_removal(song['lyrics']))             \n",
    "        else: \n",
    "            train_titles.append(song['title'])\n",
    "            X_train.append(stop_removal(song['lyrics']))\n",
    "\n",
    "# label drake as 0 and Quentin Miller as 1 in y column. \n",
    "y_train = np.zeros(len(X_train))    \n",
    "y_train[d_train_cnt:] = 1\n",
    "y_val = np.zeros(len(X_val))\n",
    "y_val[d_val_cnt:] = 1\n",
    "y_test = np.zeros(len(X_test))\n",
    "y_test[d_test_cnt:] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep track of CV accuracy of all models\n",
    "training_scores = {}\n",
    "# track the cross-validated best estimator. \n",
    "model_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_base = [ ('vect', CV(max_df=.5, ngram_range=(1, 2))), ('tfidf', TfidfTransformer())]\n",
    "param_base = {   \n",
    "    'vect__min_df': (0.002, 0.005, 0.007), \n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'tfidf__norm': ('l1', 'l2'), \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# takes a pipeline, hyperparameters, and a number of folds. \n",
    "# prints information about the grid search and returns the GridSearchCV object with the best model\n",
    "def grid_search(pipeline, param, k=8):\n",
    "    model = RandomizedSearchCV(pipeline, param, random_state=random_seed, \n",
    "                              cv=k, n_iter=8, verbose =0)\n",
    "    print(\"Performing grid search...\")\n",
    "    print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "    print(\"parameters:\", param)\n",
    "    start = time()\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"done in %0.3fs\" % (time() - start))\n",
    "    print(\"Best score: %0.3f\" % model.best_score_)\n",
    "    print(\"Best parameters set:\")\n",
    "    for param_name in sorted(param.keys()):\n",
    "        print(\"\\t%s: %r\" % (param_name, model.best_params_[param_name]))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adds results from gridsearch to global variables model_dict and score_dict \n",
    "# key should be a three letter abbreviation for the model's name. \n",
    "def track_model (key, pipeline, param, k=8):\n",
    "    global model_dict\n",
    "    global training_scores\n",
    "    grid = grid_search(pipeline, param, k)\n",
    "    model_dict[key] = grid.best_estimator_\n",
    "    training_scores[key] = grid.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=\n",
    "                    pipe_base + [('clf', LogisticRegression(class_weight='balanced', \n",
    "                               random_state=random_seed, \n",
    "                               penalty='elasticnet', \n",
    "                               solver='saga'))])\n",
    "params = param_base.copy()\n",
    "params['clf__l1_ratio'] = (0, 0.1, 0.5, 0.9)\n",
    "params['clf__C'] = (0.1, 1., 10, 100, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'clf']\n",
      "parameters: {'vect__min_df': (0.002, 0.005, 0.007), 'tfidf__use_idf': (True, False), 'tfidf__norm': ('l1', 'l2'), 'clf__l1_ratio': (0, 0.1, 0.5, 0.9), 'clf__C': (0.1, 1.0, 10, 100, 1000)}\n",
      "done in 54.324s\n",
      "Best score: 0.862\n",
      "Best parameters set:\n",
      "\tclf__C: 1000\n",
      "\tclf__l1_ratio: 0.1\n",
      "\ttfidf__norm: 'l1'\n",
      "\ttfidf__use_idf: True\n",
      "\tvect__min_df: 0.005\n"
     ]
    }
   ],
   "source": [
    "track_model('log', pipeline, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic Gradient Decent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use modified_huber to ensure we get probability estimates\n",
    "pipeline = Pipeline(steps=pipe_base + [('clf', SGDClassifier(class_weight='balanced', \n",
    "                          random_state=random_seed,  loss='modified_huber'))])\n",
    "params = param_base.copy()\n",
    "params['clf__alpha'] = (0.0001, 0.001, 0.01)\n",
    "params['clf__l1_ratio'] =(0, 0.5, 0.75, 1)\n",
    "params['clf__tol'] = (0.0001, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'clf']\n",
      "parameters: {'vect__min_df': (0.002, 0.005, 0.007), 'tfidf__use_idf': (True, False), 'tfidf__norm': ('l1', 'l2'), 'clf__alpha': (0.0001, 0.001, 0.01), 'clf__l1_ratio': (0, 0.5, 0.75, 1), 'clf__tol': (0.0001, 0.001)}\n",
      "done in 22.115s\n",
      "Best score: 0.886\n",
      "Best parameters set:\n",
      "\tclf__alpha: 0.01\n",
      "\tclf__l1_ratio: 0.75\n",
      "\tclf__tol: 0.0001\n",
      "\ttfidf__norm: 'l1'\n",
      "\ttfidf__use_idf: True\n",
      "\tvect__min_df: 0.002\n"
     ]
    }
   ],
   "source": [
    "track_model('sgd', pipeline, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use linear kernel to ensure probability estimates \n",
    "pipeline = Pipeline(steps=\n",
    "    pipe_base + [('clf', SVC(kernel='linear', random_state=random_seed, \n",
    "                             class_weight='balanced', probability=True))])\n",
    "\n",
    "params = param_base.copy()\n",
    "params['clf__C'] = (0.1, 0.5, 0.75, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'clf']\n",
      "parameters: {'vect__min_df': (0.002, 0.005, 0.007), 'tfidf__use_idf': (True, False), 'tfidf__norm': ('l1', 'l2'), 'clf__C': (0.1, 0.5, 0.75, 0.9)}\n",
      "done in 101.312s\n",
      "Best score: 0.852\n",
      "Best parameters set:\n",
      "\tclf__C: 0.5\n",
      "\ttfidf__norm: 'l2'\n",
      "\ttfidf__use_idf: True\n",
      "\tvect__min_df: 0.007\n"
     ]
    }
   ],
   "source": [
    "track_model('svc', pipeline, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=pipe_base + [('clf', RandomForestClassifier(class_weight='balanced'))])\n",
    "\n",
    "params = param_base.copy()\n",
    "params['clf__n_estimators'] = (100, 150, 200) \n",
    "params['clf__max_features'] = (50, 75, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'clf']\n",
      "parameters: {'vect__min_df': (0.002, 0.005, 0.007), 'tfidf__use_idf': (True, False), 'tfidf__norm': ('l1', 'l2'), 'clf__n_estimators': (100, 150, 200), 'clf__max_features': (50, 75, 100)}\n",
      "done in 61.597s\n",
      "Best score: 0.797\n",
      "Best parameters set:\n",
      "\tclf__max_features: 100\n",
      "\tclf__n_estimators: 100\n",
      "\ttfidf__norm: 'l1'\n",
      "\ttfidf__use_idf: False\n",
      "\tvect__min_df: 0.005\n"
     ]
    }
   ],
   "source": [
    "track_model('rfc', pipeline, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=pipe_base+[('clf', AdaBoostClassifier(random_state=random_seed))])\n",
    "\n",
    "params = param_base.copy()\n",
    "params['clf__base_estimator'] = (DTC(max_depth=1), DTC(max_depth=2), DTC(max_depth=4))\n",
    "params['clf__n_estimators'] = (100, 120, 140)\n",
    "params['clf__learning_rate'] = (1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'clf']\n",
      "parameters: {'vect__min_df': (0.002, 0.005, 0.007), 'tfidf__use_idf': (True, False), 'tfidf__norm': ('l1', 'l2'), 'clf__base_estimator': (DecisionTreeClassifier(max_depth=1), DecisionTreeClassifier(max_depth=2), DecisionTreeClassifier(max_depth=4)), 'clf__n_estimators': (100, 120, 140), 'clf__learning_rate': (1, 2)}\n",
      "done in 193.742s\n",
      "Best score: 0.807\n",
      "Best parameters set:\n",
      "\tclf__base_estimator: DecisionTreeClassifier(max_depth=2)\n",
      "\tclf__learning_rate: 1\n",
      "\tclf__n_estimators: 140\n",
      "\ttfidf__norm: 'l1'\n",
      "\ttfidf__use_idf: True\n",
      "\tvect__min_df: 0.005\n"
     ]
    }
   ],
   "source": [
    "track_model('ada', pipeline, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps=\n",
    "                    pipe_base + [('clf', GradientBoostingClassifier(random_state=random_seed))])\n",
    "\n",
    "params = param_base.copy()\n",
    "params['clf__learning_rate'] =(0.5, 0.1)\n",
    "params['clf__n_estimators'] = (50, 75, 100)\n",
    "params['clf__max_depth'] = (2, 5)\n",
    "params['clf__tol'] =  (0.0001, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'clf']\n",
      "parameters: {'vect__min_df': (0.002, 0.005, 0.007), 'tfidf__use_idf': (True, False), 'tfidf__norm': ('l1', 'l2'), 'clf__learning_rate': (0.5, 0.1), 'clf__n_estimators': (50, 75, 100), 'clf__max_depth': (2, 5), 'clf__tol': (0.0001, 0.001)}\n",
      "done in 426.798s\n",
      "Best score: 0.834\n",
      "Best parameters set:\n",
      "\tclf__learning_rate: 0.1\n",
      "\tclf__max_depth: 5\n",
      "\tclf__n_estimators: 100\n",
      "\tclf__tol: 0.001\n",
      "\ttfidf__norm: 'l2'\n",
      "\ttfidf__use_idf: False\n",
      "\tvect__min_df: 0.005\n"
     ]
    }
   ],
   "source": [
    "track_model('gbc', pipeline, params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produces the average of prediction probabilities all the models (unweighted)\n",
    "# We've removed the machine learning model from this method because it doesn't improve over the baseline accuracy. \n",
    "def ensemble_proba(corpus): \n",
    "    arr = np.zeros((len(corpus), 2*(len(model_dict))))\n",
    "    preds = np.zeros(len(corpus))\n",
    "    for ind, key in enumerate(model_dict): \n",
    "        corp = model_dict[key]['vect'].transform(corpus)\n",
    "        corp = model_dict[key]['tfidf'].transform(corp)\n",
    "        probs = model_dict[key]['clf'].predict_proba(corp)\n",
    "        arr[:, 2*ind] = probs[:, 0]\n",
    "        arr[:, 2*ind+1] = -probs[:, 1]\n",
    "    preds = np.sum(arr, axis=1)\n",
    "    return(preds/(2*len(model_dict))+.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predicts using a majority wins approach. \n",
    "# NOTE: ties favor Drake (lean towards false negatives)\n",
    "def ensemble_pred(corpus): \n",
    "    arr = np.zeros((len(corpus), (len(model_dict))))\n",
    "    preds = np.zeros(len(corpus))\n",
    "    for ind, key in enumerate(model_dict): \n",
    "        corp = model_dict[key]['vect'].transform(corpus)\n",
    "        corp = model_dict[key]['tfidf'].transform(corp)\n",
    "        arr[:, ind] = model_dict[key]['clf'].predict(corp)\n",
    "    preds = np.sum(arr, axis=1)\n",
    "    f = lambda x: 1 if (x > 3) else 0\n",
    "    return np.array([f(pred) for pred in preds])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log  train: 1.00\n",
      "log  validation: 0.92\n",
      "sgd  train: 1.00\n",
      "sgd  validation: 0.92\n",
      "svc  train: 0.98\n",
      "svc  validation: 0.83\n",
      "rfc  train: 1.00\n",
      "rfc  validation: 0.89\n",
      "ada  train: 1.00\n",
      "ada  validation: 0.89\n",
      "gbc  train: 1.00\n",
      "gbc  validation: 0.85\n"
     ]
    }
   ],
   "source": [
    "df_models = pd.DataFrame(index=training_scores.keys(), columns = ['CV', 'train', 'validation', 'test'])\n",
    "df_models['CV'] = training_scores.values()\n",
    "training = np.zeros(len(training_scores))\n",
    "validation = np.zeros(len(training_scores))\n",
    "for ind, key in enumerate(model_dict): \n",
    "    X_trans = model_dict[key]['vect'].transform(X_train)\n",
    "    X_trans = model_dict[key]['tfidf'].transform(X_trans)\n",
    "    training[ind] = accuracy_score(y_train, model_dict[key]['clf'].predict(X_trans))\n",
    "    print(key, \" train: {:.2f}\".format(accuracy_score(y_train, model_dict[key]['clf'].predict(X_trans))))\n",
    "    X_trans = model_dict[key]['vect'].transform(X_val)\n",
    "    X_trans = model_dict[key]['tfidf'].transform(X_trans)\n",
    "    validation[ind] = accuracy_score(y_val, model_dict[key]['clf'].predict(X_trans))\n",
    "    print(key, \" validation: {:.2f}\".format(accuracy_score(y_val, model_dict[key]['clf'].predict(X_trans))))\n",
    "\n",
    "\n",
    "df_models['train'] = training\n",
    "df_models['validation'] = validation\n",
    "\n",
    "# add ensemble method prediction\n",
    "df2=pd.DataFrame(np.array([float('Nan'),\n",
    "        accuracy_score(y_train,ensemble_pred(X_train)), \n",
    "        accuracy_score(y_val,ensemble_pred(X_val)),\n",
    "        float(\"Nan\")]).reshape(1,4), \n",
    "    columns=[\"CV\", 'train', 'validation', 'test'], \n",
    "    index=['ens'])\n",
    "\n",
    "df_models = df_models.append(df2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CV</th>\n",
       "      <th>train</th>\n",
       "      <th>validation</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>log</th>\n",
       "      <td>0.862143</td>\n",
       "      <td>0.996552</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sgd</th>\n",
       "      <td>0.886167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.924528</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svc</th>\n",
       "      <td>0.851727</td>\n",
       "      <td>0.975862</td>\n",
       "      <td>0.830189</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rfc</th>\n",
       "      <td>0.796547</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ada</th>\n",
       "      <td>0.807057</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gbc</th>\n",
       "      <td>0.834272</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ens</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.943396</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           CV     train  validation test\n",
       "log  0.862143  0.996552    0.924528  NaN\n",
       "sgd  0.886167  1.000000    0.924528  NaN\n",
       "svc  0.851727  0.975862    0.830189  NaN\n",
       "rfc  0.796547  1.000000    0.886792  NaN\n",
       "ada  0.807057  1.000000    0.886792  NaN\n",
       "gbc  0.834272  1.000000    0.849057  NaN\n",
       "ens       NaN  1.000000    0.943396  NaN"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best model is:  ens\n"
     ]
    }
   ],
   "source": [
    "best_key = df_models['validation'].idxmax()\n",
    "print(\"The best model is: \", best_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log  test: 0.91\n",
      "sgd  test: 0.89\n",
      "svc  test: 0.81\n",
      "rfc  test: 0.87\n",
      "ada  test: 0.85\n",
      "gbc  test: 0.83\n",
      "ens test: 0.93\n"
     ]
    }
   ],
   "source": [
    "testing = np.zeros(len(training_scores))\n",
    "for ind, key in enumerate(model_dict): \n",
    "    X_trans = model_dict[key]['vect'].transform(X_test)\n",
    "    X_trans = model_dict[key]['tfidf'].transform(X_trans)\n",
    "    testing[ind] = accuracy_score(y_test, model_dict[key]['clf'].predict(X_trans))\n",
    "    print(key, \" test: {:.2f}\".format(accuracy_score(y_test, model_dict[key]['clf'].predict(X_trans))))\n",
    "df_models[\"test\"].loc[\"ens\"] = accuracy_score(y_test, ensemble_pred(X_test))\n",
    "print(\"ens test: {:.2f}\".format(df_models[\"test\"].loc[\"ens\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Probability Predictions for *If You're Reading this it's Too Late* songs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# track the test set predictions for held out \"If You're Reading This its Too Late\" \n",
    "df_iyrtitl = pd.DataFrame(np.zeros(len(iyrtitl_titles)), index=iyrtitl_titles, columns=[\"credits\"])\n",
    "credits = ['10 Bands', \"Legend\", \"Know Yourself\", \"Used To\"]\n",
    "for name in credits:\n",
    "    df_iyrtitl.loc[name]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>credits</th>\n",
       "      <th>log_drake</th>\n",
       "      <th>log_quen</th>\n",
       "      <th>sgd_drake</th>\n",
       "      <th>sgd_quen</th>\n",
       "      <th>svc_drake</th>\n",
       "      <th>svc_quen</th>\n",
       "      <th>rfc_drake</th>\n",
       "      <th>rfc_quen</th>\n",
       "      <th>ada_drake</th>\n",
       "      <th>ada_quen</th>\n",
       "      <th>gbc_drake</th>\n",
       "      <th>gbc_quen</th>\n",
       "      <th>ens_drake</th>\n",
       "      <th>ens_quen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Legend</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.589023</td>\n",
       "      <td>0.410977</td>\n",
       "      <td>0.501303</td>\n",
       "      <td>0.498697</td>\n",
       "      <td>0.892981</td>\n",
       "      <td>0.107019</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.681710</td>\n",
       "      <td>0.318290</td>\n",
       "      <td>0.958931</td>\n",
       "      <td>0.041069</td>\n",
       "      <td>0.698991</td>\n",
       "      <td>0.301009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Energy</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.558196</td>\n",
       "      <td>0.441804</td>\n",
       "      <td>0.500547</td>\n",
       "      <td>0.499453</td>\n",
       "      <td>0.896855</td>\n",
       "      <td>0.103145</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.568291</td>\n",
       "      <td>0.431709</td>\n",
       "      <td>0.986972</td>\n",
       "      <td>0.013028</td>\n",
       "      <td>0.695143</td>\n",
       "      <td>0.304857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10 Bands</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.469871</td>\n",
       "      <td>0.530129</td>\n",
       "      <td>0.499072</td>\n",
       "      <td>0.500928</td>\n",
       "      <td>0.206581</td>\n",
       "      <td>0.793419</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.338732</td>\n",
       "      <td>0.661268</td>\n",
       "      <td>0.039196</td>\n",
       "      <td>0.960804</td>\n",
       "      <td>0.345575</td>\n",
       "      <td>0.654425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Know Yourself</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.495537</td>\n",
       "      <td>0.504463</td>\n",
       "      <td>0.499157</td>\n",
       "      <td>0.500843</td>\n",
       "      <td>0.432079</td>\n",
       "      <td>0.567921</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.448699</td>\n",
       "      <td>0.551301</td>\n",
       "      <td>0.489204</td>\n",
       "      <td>0.510796</td>\n",
       "      <td>0.504113</td>\n",
       "      <td>0.495887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No Tellin’</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.475308</td>\n",
       "      <td>0.524692</td>\n",
       "      <td>0.499211</td>\n",
       "      <td>0.500789</td>\n",
       "      <td>0.252446</td>\n",
       "      <td>0.747554</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.295010</td>\n",
       "      <td>0.704990</td>\n",
       "      <td>0.704191</td>\n",
       "      <td>0.295809</td>\n",
       "      <td>0.472694</td>\n",
       "      <td>0.527306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Madonna</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.569070</td>\n",
       "      <td>0.430930</td>\n",
       "      <td>0.500917</td>\n",
       "      <td>0.499083</td>\n",
       "      <td>0.938058</td>\n",
       "      <td>0.061942</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.657543</td>\n",
       "      <td>0.342457</td>\n",
       "      <td>0.969529</td>\n",
       "      <td>0.030471</td>\n",
       "      <td>0.717519</td>\n",
       "      <td>0.282481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6 God</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.587926</td>\n",
       "      <td>0.412074</td>\n",
       "      <td>0.501455</td>\n",
       "      <td>0.498545</td>\n",
       "      <td>0.927477</td>\n",
       "      <td>0.072523</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.557718</td>\n",
       "      <td>0.442282</td>\n",
       "      <td>0.969433</td>\n",
       "      <td>0.030567</td>\n",
       "      <td>0.705668</td>\n",
       "      <td>0.294332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Star67</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.527987</td>\n",
       "      <td>0.472013</td>\n",
       "      <td>0.500197</td>\n",
       "      <td>0.499803</td>\n",
       "      <td>0.679109</td>\n",
       "      <td>0.320891</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.462783</td>\n",
       "      <td>0.537217</td>\n",
       "      <td>0.150263</td>\n",
       "      <td>0.849737</td>\n",
       "      <td>0.495057</td>\n",
       "      <td>0.504943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Preach</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.563705</td>\n",
       "      <td>0.436295</td>\n",
       "      <td>0.501014</td>\n",
       "      <td>0.498986</td>\n",
       "      <td>0.900991</td>\n",
       "      <td>0.099009</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.460254</td>\n",
       "      <td>0.539746</td>\n",
       "      <td>0.630823</td>\n",
       "      <td>0.369177</td>\n",
       "      <td>0.622798</td>\n",
       "      <td>0.377202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wednesday Night Interlude</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.560851</td>\n",
       "      <td>0.439149</td>\n",
       "      <td>0.500506</td>\n",
       "      <td>0.499494</td>\n",
       "      <td>0.422190</td>\n",
       "      <td>0.577810</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.754214</td>\n",
       "      <td>0.245786</td>\n",
       "      <td>0.971304</td>\n",
       "      <td>0.028696</td>\n",
       "      <td>0.701511</td>\n",
       "      <td>0.298489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Used To</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.569894</td>\n",
       "      <td>0.430106</td>\n",
       "      <td>0.500964</td>\n",
       "      <td>0.499036</td>\n",
       "      <td>0.935493</td>\n",
       "      <td>0.064507</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.787120</td>\n",
       "      <td>0.212880</td>\n",
       "      <td>0.969430</td>\n",
       "      <td>0.030570</td>\n",
       "      <td>0.742150</td>\n",
       "      <td>0.257850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6 Man</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.575340</td>\n",
       "      <td>0.424660</td>\n",
       "      <td>0.501130</td>\n",
       "      <td>0.498870</td>\n",
       "      <td>0.918911</td>\n",
       "      <td>0.081089</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.605690</td>\n",
       "      <td>0.394310</td>\n",
       "      <td>0.988648</td>\n",
       "      <td>0.011352</td>\n",
       "      <td>0.693287</td>\n",
       "      <td>0.306713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Now &amp; Forever</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.519401</td>\n",
       "      <td>0.480599</td>\n",
       "      <td>0.500075</td>\n",
       "      <td>0.499925</td>\n",
       "      <td>0.391870</td>\n",
       "      <td>0.608130</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.495330</td>\n",
       "      <td>0.504670</td>\n",
       "      <td>0.976032</td>\n",
       "      <td>0.023968</td>\n",
       "      <td>0.580451</td>\n",
       "      <td>0.419549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Company</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.690607</td>\n",
       "      <td>0.309393</td>\n",
       "      <td>0.503738</td>\n",
       "      <td>0.496262</td>\n",
       "      <td>0.999254</td>\n",
       "      <td>0.000746</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.816337</td>\n",
       "      <td>0.183663</td>\n",
       "      <td>0.985702</td>\n",
       "      <td>0.014298</td>\n",
       "      <td>0.782606</td>\n",
       "      <td>0.217394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You &amp; The 6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.572909</td>\n",
       "      <td>0.427091</td>\n",
       "      <td>0.501176</td>\n",
       "      <td>0.498824</td>\n",
       "      <td>0.939432</td>\n",
       "      <td>0.060568</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.814817</td>\n",
       "      <td>0.185183</td>\n",
       "      <td>0.966425</td>\n",
       "      <td>0.033575</td>\n",
       "      <td>0.782460</td>\n",
       "      <td>0.217540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jungle</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.688426</td>\n",
       "      <td>0.311574</td>\n",
       "      <td>0.505048</td>\n",
       "      <td>0.494952</td>\n",
       "      <td>0.996588</td>\n",
       "      <td>0.003412</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.765986</td>\n",
       "      <td>0.234014</td>\n",
       "      <td>0.985607</td>\n",
       "      <td>0.014393</td>\n",
       "      <td>0.795276</td>\n",
       "      <td>0.204724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6PM in New York</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583683</td>\n",
       "      <td>0.416317</td>\n",
       "      <td>0.501428</td>\n",
       "      <td>0.498572</td>\n",
       "      <td>0.990810</td>\n",
       "      <td>0.009190</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.727846</td>\n",
       "      <td>0.272154</td>\n",
       "      <td>0.985630</td>\n",
       "      <td>0.014370</td>\n",
       "      <td>0.763233</td>\n",
       "      <td>0.236767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>How Bout Now</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.615971</td>\n",
       "      <td>0.384029</td>\n",
       "      <td>0.502133</td>\n",
       "      <td>0.497867</td>\n",
       "      <td>0.986228</td>\n",
       "      <td>0.013772</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.791827</td>\n",
       "      <td>0.208173</td>\n",
       "      <td>0.988843</td>\n",
       "      <td>0.011157</td>\n",
       "      <td>0.794167</td>\n",
       "      <td>0.205833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>My Side</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.679721</td>\n",
       "      <td>0.320279</td>\n",
       "      <td>0.503554</td>\n",
       "      <td>0.496446</td>\n",
       "      <td>0.998402</td>\n",
       "      <td>0.001598</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.796103</td>\n",
       "      <td>0.203897</td>\n",
       "      <td>0.992867</td>\n",
       "      <td>0.007133</td>\n",
       "      <td>0.816775</td>\n",
       "      <td>0.183225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           credits  log_drake  log_quen  sgd_drake  sgd_quen  \\\n",
       "Legend                         1.0   0.589023  0.410977   0.501303  0.498697   \n",
       "Energy                         0.0   0.558196  0.441804   0.500547  0.499453   \n",
       "10 Bands                       1.0   0.469871  0.530129   0.499072  0.500928   \n",
       "Know Yourself                  1.0   0.495537  0.504463   0.499157  0.500843   \n",
       "No Tellin’                     0.0   0.475308  0.524692   0.499211  0.500789   \n",
       "Madonna                        0.0   0.569070  0.430930   0.500917  0.499083   \n",
       "6 God                          0.0   0.587926  0.412074   0.501455  0.498545   \n",
       "Star67                         0.0   0.527987  0.472013   0.500197  0.499803   \n",
       "Preach                         0.0   0.563705  0.436295   0.501014  0.498986   \n",
       "Wednesday Night Interlude      0.0   0.560851  0.439149   0.500506  0.499494   \n",
       "Used To                        1.0   0.569894  0.430106   0.500964  0.499036   \n",
       "6 Man                          0.0   0.575340  0.424660   0.501130  0.498870   \n",
       "Now & Forever                  0.0   0.519401  0.480599   0.500075  0.499925   \n",
       "Company                        0.0   0.690607  0.309393   0.503738  0.496262   \n",
       "You & The 6                    0.0   0.572909  0.427091   0.501176  0.498824   \n",
       "Jungle                         0.0   0.688426  0.311574   0.505048  0.494952   \n",
       "6PM in New York                0.0   0.583683  0.416317   0.501428  0.498572   \n",
       "How Bout Now                   0.0   0.615971  0.384029   0.502133  0.497867   \n",
       "My Side                        0.0   0.679721  0.320279   0.503554  0.496446   \n",
       "\n",
       "                           svc_drake  svc_quen  rfc_drake  rfc_quen  \\\n",
       "Legend                      0.892981  0.107019       0.57      0.43   \n",
       "Energy                      0.896855  0.103145       0.66      0.34   \n",
       "10 Bands                    0.206581  0.793419       0.52      0.48   \n",
       "Know Yourself               0.432079  0.567921       0.66      0.34   \n",
       "No Tellin’                  0.252446  0.747554       0.61      0.39   \n",
       "Madonna                     0.938058  0.061942       0.67      0.33   \n",
       "6 God                       0.927477  0.072523       0.69      0.31   \n",
       "Star67                      0.679109  0.320891       0.65      0.35   \n",
       "Preach                      0.900991  0.099009       0.68      0.32   \n",
       "Wednesday Night Interlude   0.422190  0.577810       1.00      0.00   \n",
       "Used To                     0.935493  0.064507       0.69      0.31   \n",
       "6 Man                       0.918911  0.081089       0.57      0.43   \n",
       "Now & Forever               0.391870  0.608130       0.60      0.40   \n",
       "Company                     0.999254  0.000746       0.70      0.30   \n",
       "You & The 6                 0.939432  0.060568       0.90      0.10   \n",
       "Jungle                      0.996588  0.003412       0.83      0.17   \n",
       "6PM in New York             0.990810  0.009190       0.79      0.21   \n",
       "How Bout Now                0.986228  0.013772       0.88      0.12   \n",
       "My Side                     0.998402  0.001598       0.93      0.07   \n",
       "\n",
       "                           ada_drake  ada_quen  gbc_drake  gbc_quen  \\\n",
       "Legend                      0.681710  0.318290   0.958931  0.041069   \n",
       "Energy                      0.568291  0.431709   0.986972  0.013028   \n",
       "10 Bands                    0.338732  0.661268   0.039196  0.960804   \n",
       "Know Yourself               0.448699  0.551301   0.489204  0.510796   \n",
       "No Tellin’                  0.295010  0.704990   0.704191  0.295809   \n",
       "Madonna                     0.657543  0.342457   0.969529  0.030471   \n",
       "6 God                       0.557718  0.442282   0.969433  0.030567   \n",
       "Star67                      0.462783  0.537217   0.150263  0.849737   \n",
       "Preach                      0.460254  0.539746   0.630823  0.369177   \n",
       "Wednesday Night Interlude   0.754214  0.245786   0.971304  0.028696   \n",
       "Used To                     0.787120  0.212880   0.969430  0.030570   \n",
       "6 Man                       0.605690  0.394310   0.988648  0.011352   \n",
       "Now & Forever               0.495330  0.504670   0.976032  0.023968   \n",
       "Company                     0.816337  0.183663   0.985702  0.014298   \n",
       "You & The 6                 0.814817  0.185183   0.966425  0.033575   \n",
       "Jungle                      0.765986  0.234014   0.985607  0.014393   \n",
       "6PM in New York             0.727846  0.272154   0.985630  0.014370   \n",
       "How Bout Now                0.791827  0.208173   0.988843  0.011157   \n",
       "My Side                     0.796103  0.203897   0.992867  0.007133   \n",
       "\n",
       "                           ens_drake  ens_quen  \n",
       "Legend                      0.698991  0.301009  \n",
       "Energy                      0.695143  0.304857  \n",
       "10 Bands                    0.345575  0.654425  \n",
       "Know Yourself               0.504113  0.495887  \n",
       "No Tellin’                  0.472694  0.527306  \n",
       "Madonna                     0.717519  0.282481  \n",
       "6 God                       0.705668  0.294332  \n",
       "Star67                      0.495057  0.504943  \n",
       "Preach                      0.622798  0.377202  \n",
       "Wednesday Night Interlude   0.701511  0.298489  \n",
       "Used To                     0.742150  0.257850  \n",
       "6 Man                       0.693287  0.306713  \n",
       "Now & Forever               0.580451  0.419549  \n",
       "Company                     0.782606  0.217394  \n",
       "You & The 6                 0.782460  0.217540  \n",
       "Jungle                      0.795276  0.204724  \n",
       "6PM in New York             0.763233  0.236767  \n",
       "How Bout Now                0.794167  0.205833  \n",
       "My Side                     0.816775  0.183225  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predictions for iyrtitl\n",
    "for key in model_dict:\n",
    "    test = model_dict[key]['vect'].transform(iyrtitl_lyrics)\n",
    "    test = model_dict[key]['tfidf'].transform(test)\n",
    "    df_iyrtitl[key+'_drake'] = model_dict[key]['clf'].predict_proba(test)[:,0]\n",
    "    df_iyrtitl[key+'_quen'] = 1-df_iyrtitl[key+'_drake']\n",
    "df_iyrtitl['ens_drake'] = ensemble_proba(iyrtitl_lyrics)\n",
    "df_iyrtitl['ens_quen'] = 1-df_iyrtitl['ens_drake']\n",
    "df_iyrtitl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ens_drake</th>\n",
       "      <th>ens_quen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Legend</th>\n",
       "      <td>0.698991</td>\n",
       "      <td>0.301009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Energy</th>\n",
       "      <td>0.695143</td>\n",
       "      <td>0.304857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10 Bands</th>\n",
       "      <td>0.345575</td>\n",
       "      <td>0.654425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Know Yourself</th>\n",
       "      <td>0.504113</td>\n",
       "      <td>0.495887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No Tellin’</th>\n",
       "      <td>0.472694</td>\n",
       "      <td>0.527306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Madonna</th>\n",
       "      <td>0.717519</td>\n",
       "      <td>0.282481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6 God</th>\n",
       "      <td>0.705668</td>\n",
       "      <td>0.294332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Star67</th>\n",
       "      <td>0.495057</td>\n",
       "      <td>0.504943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Preach</th>\n",
       "      <td>0.622798</td>\n",
       "      <td>0.377202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Wednesday Night Interlude</th>\n",
       "      <td>0.701511</td>\n",
       "      <td>0.298489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Used To</th>\n",
       "      <td>0.742150</td>\n",
       "      <td>0.257850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6 Man</th>\n",
       "      <td>0.693287</td>\n",
       "      <td>0.306713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Now &amp; Forever</th>\n",
       "      <td>0.580451</td>\n",
       "      <td>0.419549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Company</th>\n",
       "      <td>0.782606</td>\n",
       "      <td>0.217394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>You &amp; The 6</th>\n",
       "      <td>0.782460</td>\n",
       "      <td>0.217540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Jungle</th>\n",
       "      <td>0.795276</td>\n",
       "      <td>0.204724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6PM in New York</th>\n",
       "      <td>0.763233</td>\n",
       "      <td>0.236767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>How Bout Now</th>\n",
       "      <td>0.794167</td>\n",
       "      <td>0.205833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>My Side</th>\n",
       "      <td>0.816775</td>\n",
       "      <td>0.183225</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           ens_drake  ens_quen\n",
       "Legend                      0.698991  0.301009\n",
       "Energy                      0.695143  0.304857\n",
       "10 Bands                    0.345575  0.654425\n",
       "Know Yourself               0.504113  0.495887\n",
       "No Tellin’                  0.472694  0.527306\n",
       "Madonna                     0.717519  0.282481\n",
       "6 God                       0.705668  0.294332\n",
       "Star67                      0.495057  0.504943\n",
       "Preach                      0.622798  0.377202\n",
       "Wednesday Night Interlude   0.701511  0.298489\n",
       "Used To                     0.742150  0.257850\n",
       "6 Man                       0.693287  0.306713\n",
       "Now & Forever               0.580451  0.419549\n",
       "Company                     0.782606  0.217394\n",
       "You & The 6                 0.782460  0.217540\n",
       "Jungle                      0.795276  0.204724\n",
       "6PM in New York             0.763233  0.236767\n",
       "How Bout Now                0.794167  0.205833\n",
       "My Side                     0.816775  0.183225"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best model's prediction\n",
    "df_iyrtitl[[best_key+'_drake', best_key+ \"_quen\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_proba(key, data): \n",
    "    data = model_dict[best_key]['vect'].transform(data)\n",
    "    data = model_dict[best_key]['tfidf'].transform(data)\n",
    "    return model_dict[best_key]['clf'].predict_proba(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(key, data):\n",
    "    data = model_dict[best_key]['vect'].transform(data)\n",
    "    data = model_dict[best_key]['tfidf'].transform(data)\n",
    "    return model_dict[best_key]['clf'].predict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ens'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-7e3f71453d20>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# test predictions for best model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpreds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_key\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mtest_predictions_df\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_titles\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'drake_prob'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'quen_prob'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mtest_predictions_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'prediction'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_key\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtest_predictions_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'true'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-32-277669d47053>\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(key, data)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbest_key\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'vect'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbest_key\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'tfidf'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbest_key\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'clf'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'ens'"
     ]
    }
   ],
   "source": [
    "# test predictions for best model\n",
    "preds = predict_proba(best_key, X_test)\n",
    "test_predictions_df = pd.DataFrame(preds, index=test_titles, columns=['drake_prob', 'quen_prob'])\n",
    "test_predictions_df['prediction'] = predict(best_key, X_test)\n",
    "test_predictions_df['true'] = y_test\n",
    "test_predictions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'ens'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-d9da12dd092e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdrake_tokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mquentin_tokens\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m cdf = pd.DataFrame(model_dict[best_key]['clf'].coef_.T, \n\u001b[0m\u001b[0;32m      5\u001b[0m                 \u001b[0mmodel_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbest_key\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'vect'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_feature_names\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                 columns=['Coefficients']).sort_values(['Coefficients'])\n",
      "\u001b[1;31mKeyError\u001b[0m: 'ens'"
     ]
    }
   ],
   "source": [
    "# track words that are best \"drake\" predictors, \"miller\" predictors\n",
    "drake_tokens = []\n",
    "quentin_tokens = []\n",
    "cdf = pd.DataFrame(model_dict[best_key]['clf'].coef_.T, \n",
    "                model_dict[best_key]['vect'].get_feature_names(), \n",
    "                columns=['Coefficients']).sort_values(['Coefficients'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Drake predictors \n",
    "cdf[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Quentin Miller predictors\n",
    "cdf[-10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison of Drake Albums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorganize corpus by album for further exploration of which songs are most \"Drake-like\"\n",
    "album_dict = {}\n",
    "song_titles_dict = {}\n",
    "for album in drake: \n",
    "    if len(album) < 10:\n",
    "        continue\n",
    "    album_dict[album[0]['album'].strip()] = [stop_removal(song['lyrics']) for song in album]\n",
    "    song_titles_dict[album[0]['album'].strip()] = [song['title'] for song in album]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "album_mean = {}\n",
    "for album_key in album_dict:\n",
    "    X_train = model_dict[best_key]['tfidf'].transform(model_dict[best_key]['vect'].transform(album_dict[album_key]))\n",
    "    preds = model_dict[best_key]['clf'].predict_proba(X_train)[:,0]\n",
    "    album_mean[album_key]=np.mean(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(album_mean.keys(), album_mean.values())\n",
    "plt.xticks(range(len(album_mean)), album_mean.keys(), rotation='vertical')\n",
    "plt.ylim(0.5,1)\n",
    "plt.ylabel(\"Mean probability album's songs are by 'Drake'\")\n",
    "plt.title(\"'Drakeness' of Drake albums based on 7 models\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
